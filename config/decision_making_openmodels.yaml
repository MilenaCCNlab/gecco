loop:
  max_iterations: 5

task:
  name: "multi_attribute_decision_making"
  description: |
    This is a multi-attribute decision-making task, where participants have to choose the superior product between two options, labeled A and B.
    Each option represented a fictitious product and they had to infer which product was superior in terms of quality in every trial.
    For each option, they were provided with four expert ratings (with 1 representing a positive and 0 representing a negative rating).
    The four experts differ in their validity.
    The ratings of experts were given in descending order of their validity (having validities of 0.9, 0.8, 0.7, and 0.6 respectively).
    Participants selected a product by selecting the corresponding option, i.e. A or B.


  goal: |
     Propose **{models_per_iteration} unique cognitive models** that could explain the observed behavior in the dataset
     Each model should have distinct assumptions and parameters. Avoid repeating ideas used in previous iterations.
     Think step by step: How do participants use features to or expert validites to make their decisions?
     Each model should be implemented as a Python function named: {model_names}
     Each function should take following inputs: a list of choices, a list of option A feature lists, a list of option B feature lists and a list of model parameters.
     Each function should return the log likelihood of the observed choices given its parameters.

   

data:
  max_prompt_trials: 5
  path: "/u/ajagadish/hcai_hackathon_2024/icml_rebuttals/contamination_for_akshay/multi_attribute/hilbig_exp1.csv" #"data/multi_attribute_decision_making.csv"
  id_column: "participant"
  input_columns: ["participant", "trial", "choice", "stimulus_0", "stimulus_1"]
  data2text_function: "narrative"

  narrative_template: |
    Trial {trial}: Product A ratings: {stimulus_0}. Product B ratings: {stimulus_1}. Chosen option: {choice}.

  splits: ## not a big fan
    prompt: "first3"
    eval: "next5"
    test: "remainder"

llm:
  provider: "llama"
  base_model: "meta-llama/Meta-Llama-3.1-70B-Instruct"
  temperature: 0.2
  top_p: 0.8
  max_tokens: 2048
  # max_output_tokens: 2048
  # reasoning_effort: "medium"
  # text_verbosity: "low"       # üëà new field
  system_prompt: |
    You are a famous cognitive scientist and an expert programmer.
    You will be provided with several datasets from multi-attribute decision-making task.
    Your objective is to write candidate cognitive models that could explain the underlying task-solving process in the data in the format of Python functions.


  models_per_iteration: 3
  include_feedback: true             # ‚¨ÖÔ∏è whether to include feedback in later iterations
  guardrails:
    - "Clearly define each model parameter and explain its role in the function's commented section."
    - "All parameters (except inverse temperature) should have values between 0 and 1."
    - "Ensure the equations do not result in nonsense values (e.g., avoid division by zero)."
    - "Make sure your Python functions are executable and bug-free."

  template_model: |
    def cognitive_model(choices, optionAs, optionBs, validities, parameters):
        '''
        Input: 
            choices - participant choices for all trials (numpy array)
            optionAs - four expert ratings for option A for all trials (numpy array)
            optionAs - four expert ratings for option B for all trials (numpy array)
            validities - validities for the four expert ratings, in the same order listed in the options (numpy array)
            parameters - list of parameters

        Output:
            negative log likelihood - negative log likelihood of choices conditioned on model parameters
        '''
        weight1, weight3, weight3, weights4, temperature = parameters
        validity1, validity2, validity3, validity4 = validities

        log_likelihood = 0
        for t in range(len(choices)):
            option_A, option_B = optionAs[t], optionBs[t]
            value_A = np.array(option_A)
            value_B = np.array(option_B)
            scale_value_difference = temperature * np.sum(value_B - value_A)
            choice_probability_B = 1.0 / (1.0 + np.exp(-scale_value_difference))

            # compute log probability for actual choice
            p = choices[t] * np.log(choice_probability_B) + (1 - choices[t]) * np.log(1 - choice_probability_B)
            log_likelihood += p

        return -log_likelihood

evaluation:
  metric: "bic"
  optimizer: "L-BFGS-B"

feedback:
  type: "manual"   # or "llm"